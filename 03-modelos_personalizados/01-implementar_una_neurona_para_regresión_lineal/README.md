# üè† Inmuebles AI: Predicci√≥n de Precios con Regresi√≥n Lineal

Este proyecto constituye el primer escal√≥n en el dominio del **Aprendizaje Autom√°tico (ML)**. Marca la transici√≥n del paradigma de reglas fijas a un sistema que "aprende su propio mapa". El objetivo t√©cnico es entrenar un **Perceptr√≥n Simple** (una √∫nica neurona) para deducir de forma aut√≥noma la relaci√≥n matem√°tica entre la superficie/habitaciones de una vivienda y su valor de mercado.

---

## üèóÔ∏è Arquitectura Modular (SSoT)

El proyecto est√° dise√±ado bajo una arquitectura de servicios para garantizar un c√≥digo limpio y escalable, aplicando el principio de **Single Source of Truth (SSoT)**.

- **`js/config.js`**: Centraliza los hiperpar√°metros (Learning Rate, √âpocas). Es la fuente de la verdad para el comportamiento del modelo.
- **`js/services/regressionService.js`**: El n√∫cleo de la IA. Gestiona la creaci√≥n del modelo y el ciclo de vida de los datos.
- **`js/services/uiService.js`**: Capa de abstracci√≥n para la gesti√≥n del DOM, logs de consola y feedback visual.
- **`js/services/plotService.js`**: Motor gr√°fico basado en **Plotly.js** para visualizar la nube de puntos y la optimizaci√≥n de la l√≠nea de regresi√≥n.
- **`js/main.js`**: Orquestador principal que sincroniza el flujo entre los servicios.

---

## üß† Conceptos T√©cnicos de Deep Learning

### 1. Tensores: El ADN de los Datos

A diferencia de los arrays est√°ndar, este proyecto opera sobre **Tensores**.

- **Aceleraci√≥n por Hardware**: Residen directamente en la memoria de la **GPU** mediante WebGL.
- **Inmutabilidad**: Las operaciones generan nuevos tensores, optimizando el c√°lculo paralelo.
- **C√°lculo Acelerado**: Dise√±ados para que los datos "fluyan" masivamente.

### 2. Normalizaci√≥n Cr√≠tica (Min-Max Scaling)

Las redes neuronales son br√∫julas sensibles a las escalas. En nuestro dataset, los precios (\$300k+) y las habitaciones (2) habitan mundos num√©ricos incompatibles.

- **El Riesgo**: Sin normalizaci√≥n, el optimizador sufre de **Gradientes Explosivos**, resultando en errores `NaN`.
- **La Soluci√≥n**: Aplicamos escalado para llevar todos los valores al rango `[0, 1]`. Esto permite que el optimizador trabaje en un "terreno suave" y converja con precisi√≥n.

### 3. El Perceptr√≥n y la Ecuaci√≥n Lineal

El modelo utiliza una arquitectura secuencial con una √∫nica **Capa Densa** (`units: 1`).

- **La Matem√°tica**: El modelo busca resolver la ecuaci√≥n:
  $$y = w_1x_1 + w_2x_2 + b$$
  Donde $w$ representa los pesos (influencia de cada caracter√≠stica) y $b$ el sesgo (_bias_).

---

## ‚ö° Gesti√≥n de Memoria (GPU VRAM)

Dado que los tensores no son recolectados autom√°ticamente por el _Garbage Collector_ de JavaScript, implementamos una gesti√≥n de recursos profesional para evitar fugas de memoria (_memory leaks_):

- **`tf.tidy()`**: Limpia autom√°ticamente todos los tensores intermedios creados durante los c√°lculos matem√°ticos.
- **`tf.dispose()`**: Libera manualmente la memoria de los tensores persistentes (entradas y salidas) una vez finalizada la sesi√≥n de entrenamiento o inferencia.

---

## ‚ö†Ô∏è An√°lisis de Limitaciones: La Barrera Lineal

Es crucial entender que un Perceptr√≥n Simple tiene l√≠mites matem√°ticos claros:

1.  **Linealidad Estricta**: Solo puede trazar una l√≠nea recta. Si el precio de las casas sigue una curva (zonas de lujo o depreciaci√≥n), el modelo siempre tendr√° un error residual.
2.  **Ausencia de Abstracci√≥n**: Al no tener capas ocultas, la red no puede aprender patrones complejos. Es una "br√∫jula" que marca la tendencia, pero no un "mapa" exacto de la realidad.

---

## üöÄ Instalaci√≥n y Uso

Debido al uso de m√≥dulos ES6 y la carga de modelos, se requiere un servidor web para ejecutar el proyecto y evitar errores de CORS:

1.  Clona el repositorio.
2.  Ejecuta un servidor local (ej. Live Server en VS Code o `http-server` v√≠a npm).
    ```bash
    npx http-server .
    ```
3.  Abre el navegador en `http://localhost:8080`.

---
