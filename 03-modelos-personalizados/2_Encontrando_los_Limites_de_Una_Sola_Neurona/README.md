# üß¨ Proyecto 2: Los L√≠mites de la Linealidad (Underfitting)

Este proyecto es un experimento de **Ingenier√≠a de Machine Learning** dise√±ado para evidenciar el concepto de **Underfitting** (subajuste). El objetivo t√©cnico es intentar que un **Perceptr√≥n Simple** (una √∫nica neurona) aprenda una relaci√≥n cuadr√°tica ($y = x^2$), demostrando que la arquitectura es el factor limitante del conocimiento, independientemente del volumen de datos o el tiempo de entrenamiento.

---

## üèóÔ∏è Arquitectura del Sistema (Modularidad SSoT)

El c√≥digo sigue el principio de **Responsabilidad √önica (SRP)** y utiliza un enfoque de **Single Source of Truth (SSoT)** para la configuraci√≥n global:

| M√≥dulo                                 | Responsabilidad                                                             |
| :------------------------------------- | :-------------------------------------------------------------------------- |
| **`js/config.js`**                     | Gesti√≥n de hiperpar√°metros y generaci√≥n del dataset cuadr√°tico (SSoT).      |
| **`js/services/regressionService.js`** | Ciclo de vida del modelo, normalizaci√≥n y l√≥gica de Tensores (Cerebro IA).  |
| **`js/services/uiService.js`**         | Abstracci√≥n de la interfaz, manejo de logs de telemetr√≠a y estados del DOM. |
| **`js/services/plotService.js`**       | Visualizaci√≥n din√°mica en tiempo real mediante **Plotly.js**.               |
| **`js/main.js`**                       | Orquestador principal que dirige el pipeline de entrenamiento e inferencia. |

---

## üî¨ El Experimento: Linealidad vs. Curvatura

### El Desaf√≠o Matem√°tico

Un perceptr√≥n simple sin capas ocultas ni funciones de activaci√≥n no lineales es, matem√°ticamente, una calculadora lineal. La neurona est√° restringida a resolver la ecuaci√≥n de primer grado:

$$y = wx + b$$

Esto genera un **hiperplano** (en este caso, una l√≠nea recta). En este laboratorio, alimentamos al modelo con una par√°bola perfecta ($x, x^2$).

### Resultado: "Fracaso de Arquitectura"

Al finalizar el ciclo de aprendizaje, el sistema experimenta los siguientes fen√≥menos t√©cnicos:

1. **Rigidez Estructural:** La l√≠nea roja (predicci√≥n) no puede "doblarse". Traza la mejor l√≠nea promedio que minimiza la distancia a todos los puntos, pero falla en la trayectoria.
2. **Estancamiento del Gradiente:** La funci√≥n de p√©rdida (_Loss_) alcanza un l√≠mite (_plateau_) donde deja de bajar; el optimizador ya no encuentra una pendiente de mejora.
3. **Error en Inferencia:** Al solicitar una predicci√≥n para $x = 7$, el modelo entrega un valor err√°tico (aprox. 30 en lugar de 49), confirmando un **Sesgo Lineal Inmanente**.

---

## ‚ö° Gesti√≥n Avanzada de Memoria (GPU)

### Resoluci√≥n del Error de Backend

Durante el desarrollo se corrigi√≥ el error cr√≠tico: `Cannot read properties of undefined (reading 'backend')`.

- **La Causa:** El uso de `tf.tidy()` envolv√≠a los tensores de normalizaci√≥n ($min$ y $max$) necesarios para la inferencia. Al finalizar el bloque `tidy`, TensorFlow eliminaba estos tensores de la **VRAM**, dejando las referencias del servicio vac√≠as para futuras predicciones.
- **La Soluci√≥n:** Se implement√≥ `.dataSync()[0]` para transferir los valores escalares de la **GPU** a variables nativas de **JavaScript**. Esto garantiza que los par√°metros de normalizaci√≥n sobrevivan al ciclo de limpieza de memoria.

> **Nota T√©cnica:** La **Inferencia** es el proceso de aplicar el conocimiento aprendido a datos nuevos. Sin una des-normalizaci√≥n precisa basada en datos persistentes, el resultado de la neurona ser√≠a incomprensible para el usuario.

---

## üöÄ Ejecuci√≥n del Laboratorio

Debido al uso de m√≥dulos ES6 y pol√≠ticas de seguridad del navegador, el proyecto requiere un servidor local:

1.  **Levantar Servidor:**
    ```bash
    npx http-server . --cors
    ```
2.  **Monitoreo:** Abre la consola del navegador para ver la telemetr√≠a del entrenamiento.
3.  **Visualizaci√≥n:** Observa en la gr√°fica c√≥mo la l√≠nea de predicci√≥n intenta, sin √©xito, ajustarse a la curvatura de los datos reales.

---

**Conclusi√≥n Did√°ctica:** Este experimento demuestra que para resolver problemas complejos del mundo real, no basta con "m√°s datos"; necesitamos **Arquitecturas No Lineales** (MLP) y funciones de activaci√≥n como **ReLU**.
